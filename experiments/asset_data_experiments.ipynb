{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.conf import SparkConf\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import *\n",
    "from functools import reduce\n",
    "import json\n",
    "import glob\n",
    "import tempfile\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bronze_df = spark.read.parquet(\"../data/output/bronze/asset_bronze.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_columns  = {'general':[f'AS{i}' for i in range(1,15) if f'AS{i}' in bronze_df.columns],\n",
    "                    'obligor_info':[f'AS{i}' for i in range(15,50) if f'AS{i}' in bronze_df.columns],\n",
    "                    'loan_info':[f'AS{i}' for i in range(50,80) if f'AS{i}' in bronze_df.columns],\n",
    "                    'interest_rate':[f'AS{i}' for i in range(80,100) if f'AS{i}' in bronze_df.columns],\n",
    "                    'financial_info':[f'AS{i}' for i in range(100,115) if f'AS{i}' in bronze_df.columns],\n",
    "                    'performance_info':[f'AS{i}' for i in range(115,146) if f'AS{i}' in bronze_df.columns]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_columns[\"general\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bronze_df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_col_type = {'date': ['AS1',\n",
    "  'AS19',\n",
    "  'AS20',\n",
    "  'AS31',\n",
    "  'AS50',\n",
    "  'AS51',\n",
    "  'AS67',\n",
    "  'AS70',\n",
    "  'AS71',\n",
    "  'AS87',\n",
    "  'AS91',\n",
    "  'AS112',\n",
    "  'AS124',\n",
    "  'AS127',\n",
    "  'AS130',\n",
    "  'AS133',\n",
    "  'AS134',\n",
    "  'AS137'],\n",
    " 'string': ['AS2',\n",
    "  'AS3',\n",
    "  'AS4',\n",
    "  'AS5',\n",
    "  'AS6',\n",
    "  'AS7',\n",
    "  'AS8',\n",
    "  'AS15',\n",
    "  'AS16',\n",
    "  'AS17',\n",
    "  'AS18',\n",
    "  'AS21',\n",
    "  'AS22',\n",
    "  'AS24',\n",
    "  'AS25',\n",
    "  'AS26',\n",
    "  'AS32',\n",
    "  'AS33',\n",
    "  'AS34',\n",
    "  'AS35',\n",
    "  'AS36',\n",
    "  'AS42',\n",
    "  'AS43',\n",
    "  'AS45',\n",
    "  'AS52',\n",
    "  'AS57',\n",
    "  'AS58',\n",
    "  'AS59',\n",
    "  'AS62',\n",
    "  'AS65',\n",
    "  'AS68',\n",
    "  'AS83',\n",
    "  'AS84',\n",
    "  'AS89',\n",
    "  'AS92',\n",
    "  'AS94',\n",
    "  'AS111',\n",
    "  'AS123',\n",
    "  'AS129'],\n",
    " 'boolean': ['AS23',\n",
    "  'AS27',\n",
    "  'AS28',\n",
    "  'AS29',\n",
    "  'AS30',\n",
    "  'AS37',\n",
    "  'AS38',\n",
    "  'AS39',\n",
    "  'AS40',\n",
    "  'AS41',\n",
    "  'AS44',\n",
    "  'AS53',\n",
    "  'AS54',\n",
    "  'AS55',\n",
    "  'AS56',\n",
    "  'AS60',\n",
    "  'AS61',\n",
    "  'AS63',\n",
    "  'AS64',\n",
    "  'AS66',\n",
    "  'AS69',\n",
    "  'AS80',\n",
    "  'AS81',\n",
    "  'AS82',\n",
    "  'AS85',\n",
    "  'AS86',\n",
    "  'AS88',\n",
    "  'AS90',\n",
    "  'AS93',\n",
    "  'AS100',\n",
    "  'AS101',\n",
    "  'AS102',\n",
    "  'AS103',\n",
    "  'AS104',\n",
    "  'AS105',\n",
    "  'AS106',\n",
    "  'AS107',\n",
    "  'AS108',\n",
    "  'AS109',\n",
    "  'AS110',\n",
    "  'AS115',\n",
    "  'AS116',\n",
    "  'AS117',\n",
    "  'AS118',\n",
    "  'AS119',\n",
    "  'AS120',\n",
    "  'AS121',\n",
    "  'AS122',\n",
    "  'AS125',\n",
    "  'AS126',\n",
    "  'AS128',\n",
    "  'AS131',\n",
    "  'AS132',\n",
    "  'AS135',\n",
    "  'AS136',\n",
    "  'AS138']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datetime dimension table\n",
    "def process_dates(df,col_types_dict):\n",
    "    date_cols = [c for c in col_types_dict[\"date\"] if c in df.columns]\n",
    "\n",
    "    new_df= (\n",
    "        df.select(F.explode(F.array(date_cols)).alias(\"date_col\"))\n",
    "        .dropDuplicates()\n",
    "        .withColumn(\"unix_date\", F.unix_timestamp(F.col(\"date_col\")))\n",
    "        .withColumn(\"year\", F.year(F.col(\"date_col\")))\n",
    "        .withColumn(\"month\", F.month(F.col(\"date_col\")))\n",
    "        .withColumn(\"quarter\", F.quarter(F.col(\"date_col\")))\n",
    "        .withColumn(\"WoY\", F.weekofyear(F.col(\"date_col\")))\n",
    "        .withColumn(\"day\", F.dayofmonth(F.col(\"date_col\")))\n",
    "    )\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Obligor Info dimension table\n",
    "def process_obligor_info(df, cols_dict):\n",
    "    new_df = (\n",
    "        df.select(assets_columns[\"general\"] + assets_columns[\"obligor_info\"])\n",
    "        .withColumn(\"tmp_AS1\", F.unix_timestamp(F.col(\"AS1\"))).drop(\"AS1\").withColumnRenamed(\"tmp_AS1\", \"AS1\")\n",
    "        .withColumn(\"tmp_AS19\", F.unix_timestamp(F.col(\"AS19\"))).drop(\"AS19\").withColumnRenamed(\"tmp_AS19\", \"AS19\")\n",
    "        .withColumn(\"tmp_AS20\", F.unix_timestamp(F.col(\"AS20\"))).drop(\"AS20\").withColumnRenamed(\"tmp_AS20\", \"AS20\")\n",
    "        .withColumn(\"tmp_AS31\", F.unix_timestamp(F.col(\"AS31\"))).drop(\"AS31\").withColumnRenamed(\"tmp_AS31\", \"AS31\")\n",
    "    )\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Loan Info dimension table\n",
    "def process_loan_info(df, cols_dict):\n",
    "    new_df = (\n",
    "        df.select(assets_columns[\"general\"] + assets_columns[\"loan_info\"])\n",
    "        .withColumn(\"tmp_AS1\", F.unix_timestamp(F.col(\"AS1\"))).drop(\"AS1\").withColumnRenamed(\"tmp_AS1\", \"AS1\")\n",
    "        .withColumn(\"tmp_AS50\", F.unix_timestamp(F.col(\"AS50\"))).drop(\"AS50\").withColumnRenamed(\"tmp_AS50\", \"AS50\")\n",
    "        .withColumn(\"tmp_AS51\", F.unix_timestamp(F.col(\"AS51\"))).drop(\"AS51\").withColumnRenamed(\"tmp_AS51\", \"AS51\")\n",
    "        .withColumn(\"tmp_AS67\", F.unix_timestamp(F.col(\"AS67\"))).drop(\"AS67\").withColumnRenamed(\"tmp_AS67\", \"AS67\")\n",
    "        .withColumn(\"tmp_AS70\", F.unix_timestamp(F.col(\"AS70\"))).drop(\"AS70\").withColumnRenamed(\"tmp_AS70\", \"AS70\")\n",
    "        .withColumn(\"tmp_AS71\", F.unix_timestamp(F.col(\"AS71\"))).drop(\"AS71\").withColumnRenamed(\"tmp_AS71\", \"AS71\")\n",
    "    )\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Interest Rate dimension table\n",
    "def process_interest_rate(df, cols_dict):\n",
    "    new_df = (\n",
    "        df.select(assets_columns[\"general\"] + assets_columns[\"interest_rate\"])\n",
    "        .withColumn(\"tmp_AS1\", F.unix_timestamp(F.col(\"AS1\"))).drop(\"AS1\").withColumnRenamed(\"tmp_AS1\", \"AS1\")\n",
    "        .withColumn(\"tmp_AS87\", F.unix_timestamp(F.col(\"AS87\"))).drop(\"AS87\").withColumnRenamed(\"tmp_AS87\", \"AS87\")\n",
    "        .withColumn(\"tmp_AS91\", F.unix_timestamp(F.col(\"AS91\"))).drop(\"AS91\").withColumnRenamed(\"tmp_AS91\", \"AS91\")\n",
    "    )\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Financial Info dimension table\n",
    "def process_financial_info(df, cols_dict):\n",
    "    new_df = (\n",
    "        df.select(assets_columns[\"general\"] + assets_columns[\"financial_info\"])\n",
    "        .withColumn(\"tmp_AS1\", F.unix_timestamp(F.col(\"AS1\"))).drop(\"AS1\").withColumnRenamed(\"tmp_AS1\", \"AS1\")\n",
    "        .withColumn(\"tmp_AS112\", F.unix_timestamp(F.col(\"AS112\"))).drop(\"AS112\").withColumnRenamed(\"tmp_AS112\", \"AS112\")\n",
    "    )\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Performance Info dimension table\n",
    "def process_performance_info(df, cols_dict):\n",
    "    new_df = (\n",
    "        df.select(assets_columns[\"general\"] + assets_columns[\"performance_info\"])\n",
    "        .withColumn(\"tmp_AS1\", F.unix_timestamp(F.col(\"AS1\"))).drop(\"AS1\").withColumnRenamed(\"tmp_AS1\", \"AS1\")\n",
    "        .withColumn(\"tmp_AS124\", F.unix_timestamp(F.col(\"AS124\"))).drop(\"AS124\").withColumnRenamed(\"tmp_AS124\", \"AS124\")\n",
    "        .withColumn(\"tmp_AS127\", F.unix_timestamp(F.col(\"AS127\"))).drop(\"AS127\").withColumnRenamed(\"tmp_AS127\", \"AS127\")\n",
    "        .withColumn(\"tmp_AS130\", F.unix_timestamp(F.col(\"AS130\"))).drop(\"AS130\").withColumnRenamed(\"tmp_AS130\", \"AS130\")\n",
    "        .withColumn(\"tmp_AS133\", F.unix_timestamp(F.col(\"AS133\"))).drop(\"AS133\").withColumnRenamed(\"tmp_AS133\", \"AS133\")\n",
    "        .withColumn(\"tmp_AS134\", F.unix_timestamp(F.col(\"AS134\"))).drop(\"AS134\").withColumnRenamed(\"tmp_AS134\", \"AS134\")\n",
    "        .withColumn(\"tmp_AS137\", F.unix_timestamp(F.col(\"AS137\"))).drop(\"AS137\").withColumnRenamed(\"tmp_AS137\", \"AS137\")\n",
    "    )\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write down examples\n",
    "df = process_dates(bronze_df,asset_col_type)\n",
    "df.write.parquet(\"../data/output/silver/assets/datetime.parquet\")\n",
    "\n",
    "df = process_loan_info(bronze_df,assets_columns)\n",
    "df.write.parquet(\"../data/output/silver/assets/loan_info.parquet\")\n",
    "\n",
    "df = process_obligor_info(bronze_df,assets_columns)\n",
    "df.write.parquet(\"../data/output/silver/assets/obligor_info.parquet\")\n",
    "\n",
    "df = process_financial_info(bronze_df,assets_columns)\n",
    "df.write.parquet(\"../data/output/silver/assets/financial_info.parquet\")\n",
    "\n",
    "df = process_interest_rate(bronze_df,assets_columns)\n",
    "df.write.parquet(\"../data/output/silver/assets/interest_rate.parquet\")\n",
    "\n",
    "df = process_performance_info(bronze_df,assets_columns)\n",
    "df.write.parquet(\"../data/output/silver/assets/performance_info.parquet\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
